{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "Convolutional neural networks started a completely new approach of machine learning generally called as \"deep learning\". In principle, it is based on idea that tasks can be solved by devising a suitable architecture that learns to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone network 1: AlexNet\n",
    "\n",
    "AlexNet was presented in the NeurIPS 2012 conference and that single paper started the revolution in ML. The paper introduced various concepts for training many convolutional layers of neurons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone network 2: VGGNet\n",
    "\n",
    "In their paper the Oxford group investigated various strategies to build a better backbone network for image classification and proposed VGGNet which is many ways simplified version of AlexNet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More backbones\n",
    "A bunch of pre-trained backbone networks have been made available in Keras (https://keras.io/api/applications/) and include, for example, various versions of the ResNet, Inception, MobileNet and EfficientNet. You may easily use them in your applications. Often VGG16 performs rather well in any application and is thus a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 1: CNN with some AlexNet flavors (MNIST Digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(f' Min y (class) values is {np.min(y_test)} and max {np.max(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential()\n",
    "\n",
    "model2.add(keras.layers.Input(shape=(28,28,1)))\n",
    "print(model2.output_shape)\n",
    "           \n",
    "# Convolution layer\n",
    "model2.add(keras.layers.Conv2D(16,kernel_size=(5,5),strides=(2,2)))\n",
    "print(model2.output_shape)\n",
    "\n",
    "# Flatten input image to a vector\n",
    "model2.add(keras.layers.Flatten())\n",
    "print(model2.output_shape)\n",
    "\n",
    "# Add a full connected layer\n",
    "model2.add(keras.layers.Dense(10, activation='sigmoid'))\n",
    "print(model2.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This loss takes care of one-hot encoding (see https://keras.io/api/losses/)\n",
    "#loss_fn2 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "##loss_fn = tf.keras.losses.MeanSquaredError(from_logits=True)\n",
    "#model2.compile(optimizer='adam',\n",
    "#              loss=loss_fn2,\n",
    "#              metrics=['accuracy'])\n",
    "#model2.summary()\n",
    "\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert training data to format assumed by a convolutional filter (add one more dimension to make it explicit) and convert y explicitly to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(x_train, y_train_cat, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = model2.predict(x_test)\n",
    "y_test_hat = y_test_hat[0:10,:]\n",
    "#print(np.maxind(y_test_hat))\n",
    "print(y_test[0:10])\n",
    "\n",
    "print(np.argmax(y_test_hat,axis=1))\n",
    "model2.evaluate(x_test,  y_test_cat, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is with more tricks and flavors but we need to learn about backbone networks first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With more tricks (ReLu and MaxPooling)\n",
    "model3 = tf.keras.models.Sequential()\n",
    "\n",
    "model3.add(keras.layers.Input(shape=(28,28,1)))\n",
    "print(model3.output_shape)\n",
    "           \n",
    "# Convolution layer 1\n",
    "model3.add(keras.layers.Conv2D(16,kernel_size=(3,3)))\n",
    "print(model3.output_shape)\n",
    "\n",
    "# Max pooling\n",
    "model3.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "print(model3.output_shape)\n",
    "\n",
    "# Convolution layer 2\n",
    "model3.add(keras.layers.Conv2D(32,kernel_size=(3,3)))\n",
    "print(model3.output_shape)\n",
    "\n",
    "# Max pooling\n",
    "model3.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "print(model3.output_shape)\n",
    "\n",
    "# Flatten input image to a vector\n",
    "model3.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "print(model3.output_shape)\n",
    "\n",
    "# Add dropout \"layer\"\n",
    "model3.add(keras.layers.Dropout(0.2))\n",
    "print(model3.output_shape)\n",
    "\n",
    "# Add a full connected layer\n",
    "model3.add(keras.layers.Dense(10, activation='softmax'))\n",
    "print(model3.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(x_train, y_train_cat, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoders\n",
    "Autoencoder architecture is a good starting point to understand recent developments as many great ideas can be derived from it.\n",
    "\n",
    "### Demo: autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepFakes\n",
    "\n",
    "See: https://www.alanzucconi.com/2018/03/14/understanding-the-technology-behind-deepfakes/\n",
    "\n",
    "Video: https://www.youtube.com/watch?v=OmB7fmi8JwY\n",
    "\n",
    "Code: plenty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversarial Network (GAN)\n",
    "\n",
    "StyleGAN: https://en.wikipedia.org/wiki/StyleGAN\n",
    "\n",
    "Code: https://github.com/NVlabs/stylegan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's all about data - crazy ideas to collect data\n",
    "\n",
    "Frozen people: https://mannequin-depth.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural language processing - Transformers\n",
    "\n",
    "The most amazing results in AI occur in NLP at the moment. Especially the results of large scale language models are incredible (as of Aug 2022) and now tranformer architectures are quickly apodted in vision and other fields as well.\n",
    "\n",
    "Question & answer demo: https://www.pragnakalp.com/demos/BERT-NLP-QnA-Demo/\n",
    "\n",
    "Text generation: https://talktotransformer.com/\n",
    "\n",
    "DALL-E: https://gpt3demo.com/apps/openai-dall-e\n",
    "\n",
    "DALL-E 2: https://openai.com/dall-e-2/\n",
    "\n",
    "PaLM: https://thenextweb.com/news/google-palm-ai-sucks-at-telling-jokes-but-great-at-analyzing-them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "TensorFlow Tutorials. URL: https://www.tensorflow.org/tutorials\n",
    "\n",
    "Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton (2012): \"ImageNet Classification with Deep Convolutional Neural Networks\". In Proc. of the NeurIPS. URL: https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\n",
    "\n",
    "Karen Simonyan, Andrew Zisserman (2015): \"Very Deep Convolutional Networks for Large-Scale Image Recognition\". In Proc. of the ICLR. URL: https://arxiv.org/abs/1409.1556"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
